{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48a105-0d4a-4c44-9334-42f750e0a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "logging.getLogger('pgmpy').setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"networkx.utils.backends\")\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import random\n",
    "import time\n",
    "from Decom_Tree import *\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.linalg import inv, det\n",
    "from pgmpy.global_vars import logger\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.factors.continuous import LinearGaussianCPD\n",
    "from pgmpy.models import LinearGaussianBayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589ab5d-0bf5-48da-a126-bafac94ef400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cpds(bn, loc=0, scale=0.1, inplace=False, seed=None):\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from pgmpy.factors.continuous import LinearGaussianCPD\n",
    "\n",
    "    seed = seed if seed is not None else int(time.time() * 1000) % (2**32)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    cpds = []\n",
    "    for i, var in enumerate(bn.nodes()):\n",
    "        parents = bn.get_parents(var)\n",
    "        cpd = LinearGaussianCPD.get_random(\n",
    "            variable=var,\n",
    "            evidence=parents,\n",
    "            loc=loc,\n",
    "            scale=scale,\n",
    "            seed=seed + i\n",
    "        )\n",
    "        cpds.append(cpd)\n",
    "\n",
    "    if inplace:\n",
    "        bn.add_cpds(*cpds)\n",
    "    else:\n",
    "        return cpds\n",
    "\n",
    "\n",
    "def kl_divergence(mu1, cov1, mu2, cov2):\n",
    "    \"\"\"\n",
    "    Compute the Kullback–Leibler (KL) divergence between two multivariate Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        mu1 (ndarray): Mean vector of the first distribution.\n",
    "        cov1 (ndarray): Covariance matrix of the first distribution.\n",
    "        mu2 (ndarray): Mean vector of the second distribution.\n",
    "        cov2 (ndarray): Covariance matrix of the second distribution.\n",
    "        \n",
    "    Returns:\n",
    "        float: KL divergence D_KL(N(mu1, cov1) || N(mu2, cov2))\n",
    "    \"\"\"\n",
    "    d = len(mu1)  # Dimensionality of the distributions\n",
    "    term1 = np.trace(np.dot(inv(cov2), cov1))  # Tr(Sigma_2^-1 * Sigma_1)\n",
    "    term2 = np.dot(np.dot((mu2 - mu1).T, inv(cov2)), (mu2 - mu1))  # (mu2 - mu1)^T * Sigma_2^-1 * (mu2 - mu1)\n",
    "    term3 = np.log(det(cov2) / det(cov1))  # log(det(Sigma_2) / det(Sigma_1))\n",
    "    kl_divergence = 0.5 * (term1 + term2 - d + term3)\n",
    "    return kl_divergence\n",
    "\n",
    "\n",
    "def hellinger_distance(mu1, cov1, mu2, cov2):\n",
    "    \"\"\"\n",
    "    Compute the Hellinger distance between two multivariate Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        mu1 (ndarray): Mean vector of the first distribution.\n",
    "        cov1 (ndarray): Covariance matrix of the first distribution.\n",
    "        mu2 (ndarray): Mean vector of the second distribution.\n",
    "        cov2 (ndarray): Covariance matrix of the second distribution.\n",
    "        \n",
    "    Returns:\n",
    "        float: Hellinger distance H(N(mu1, cov1), N(mu2, cov2))\n",
    "    \"\"\"\n",
    "    # Compute the determinants of the covariance matrices\n",
    "    det_cov1 = det(cov1)\n",
    "    det_cov2 = det(cov2)\n",
    "    \n",
    "    # Compute the average of the two covariance matrices\n",
    "    avg_cov = (cov1 + cov2) / 2\n",
    "    \n",
    "    # Compute the exponent term in the Hellinger distance formula\n",
    "    diff_mu = mu1 - mu2\n",
    "    term = np.dot(np.dot(diff_mu.T, inv(avg_cov)), diff_mu)  # (mu1 - mu2)^T * Sigma_avg^-1 * (mu1 - mu2)\n",
    "    exponent = -0.125 * term\n",
    "    \n",
    "    # Compute the squared Hellinger distance\n",
    "    hellinger_squared = 1 - (det_cov1 ** 0.25) * (det_cov2 ** 0.25) / (det(avg_cov) ** 0.5) * np.exp(exponent)\n",
    "    return np.sqrt(hellinger_squared)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wasserstein2_distance(mu1, cov1, mu2, cov2):\n",
    "    \"\"\"\n",
    "    Compute the 2-Wasserstein distance between two multivariate Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        mu1 (ndarray): Mean vector of the first distribution.\n",
    "        cov1 (ndarray): Covariance matrix of the first distribution.\n",
    "        mu2 (ndarray): Mean vector of the second distribution.\n",
    "        cov2 (ndarray): Covariance matrix of the second distribution.\n",
    "        \n",
    "    Returns:\n",
    "        float: Wasserstein-2 distance W2(N(mu1, cov1), N(mu2, cov2))\n",
    "    \"\"\"\n",
    "    diff_mu = mu1 - mu2\n",
    "    # 均值部分\n",
    "    mean_term = np.dot(diff_mu.T, diff_mu)\n",
    "    \n",
    "    # 协方差部分\n",
    "    cov_prod_sqrt = sqrtm(np.dot(sqrtm(cov2), np.dot(cov1, sqrtm(cov2))))\n",
    "    # 由于数值原因，sqrtm 可能返回复数，取实部\n",
    "    cov_prod_sqrt = cov_prod_sqrt.real\n",
    "    \n",
    "    cov_term = np.trace(cov1 + cov2 - 2 * cov_prod_sqrt)\n",
    "    \n",
    "    return np.sqrt(mean_term + cov_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8ee58-e657-4601-bb7e-d8d7a17781c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [500, 1000, 2500, 5000, 7500, 10000]\n",
    "networks = [\"ecoli70\", \"magic-niab\", \"magic-irri\", \"arth150\"]\n",
    "\n",
    "# 条件数汇总表格\n",
    "cond_summary = pd.DataFrame(index=sample_sizes, columns=networks)\n",
    "\n",
    "# 原有结果 DataFrame\n",
    "columns = pd.MultiIndex.from_product(\n",
    "    [networks, sample_sizes, [\"klPQ\", \"hellinger\", \"wasserstein-2\"]]\n",
    ")\n",
    "result_continue = pd.DataFrame(columns=columns)\n",
    "repeat_num = 100\n",
    "\n",
    "cond_all = {net: {size: [] for size in sample_sizes} for net in networks}\n",
    "\n",
    "for file in networks:\n",
    "    print(f\"Processing {file}...\")\n",
    "    model = get_example_model(file)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(model.nodes)\n",
    "    G.add_edges_from(model.edges)\n",
    "    decom = Graph_Decom(G)\n",
    "    atoms = decom.Decom()\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        succ_num = repeat_num\n",
    "        row = 0\n",
    "        cond_list = []  # 存放每次实验 cov_learn 条件数\n",
    "        \n",
    "        while succ_num:\n",
    "            # === 原 BN 拟合逻辑不动 ===\n",
    "            bn = LinearGaussianBayesianNetwork()\n",
    "            bn.add_nodes_from(list(G.nodes))\n",
    "            bn.add_edges_from(list(G.edges)) \n",
    "            get_random_cpds(bn, inplace=True)\n",
    "            df = bn.simulate(sample_size)\n",
    "            \n",
    "            learn_bn = LinearGaussianBayesianNetwork()\n",
    "            learn_bn.add_nodes_from(list(G.nodes))\n",
    "            learn_bn.add_edges_from(list(G.edges))\n",
    "            learn_bn.cpds = []\n",
    "            Traverse = []\n",
    "            for i in atoms:\n",
    "                sub_model = LinearGaussianBayesianNetwork(list(G.subgraph(list(i)).edges))\n",
    "                sub_model.add_nodes_from(i)\n",
    "                sub_model.cpds = []\n",
    "                sub_model.fit(df[list(i)])\n",
    "                for node in i:\n",
    "                    if node not in Traverse:\n",
    "                        if len(model.get_parents(node)) == len(sub_model.get_parents(node)):\n",
    "                            Traverse.append(node)\n",
    "                            learn_bn.add_cpds(sub_model.get_cpds(node))\n",
    "            \n",
    "            # === 新增：计算 cov_learn 条件数 ===\n",
    "            _, cov_learn = learn_bn.to_joint_gaussian()\n",
    "            cond_number = np.linalg.cond(cov_learn)\n",
    "            cond_list.append(cond_number)\n",
    "            cond_all[file][sample_size].append(cond_number)\n",
    "            \n",
    "            # === 原 KL/Hellinger/W2 逻辑不动 ===\n",
    "            mean, cov = bn.to_joint_gaussian()\n",
    "            mean_learn, cov_learn = learn_bn.to_joint_gaussian()\n",
    "            kl_value = kl_divergence(mean, cov, mean_learn, cov_learn)\n",
    "            hellinger_value = hellinger_distance(mean, cov, mean_learn, cov_learn)\n",
    "            wasserstein_value = wasserstein2_distance(mean, cov, mean_learn, cov_learn)\n",
    "\n",
    "            for metric_name, value in [(\"klPQ\", kl_value), (\"hellinger\", hellinger_value), (\"wasserstein-2\", wasserstein_value)]:\n",
    "                result_continue.loc[row + 1, (file, sample_size, metric_name)] = round(value, 4)\n",
    "                \n",
    "            succ_num -= 1\n",
    "            row += 1\n",
    "        \n",
    "        # 汇总条件数 → mean ± std， 条件数的均值，方差\n",
    "        mean_cond = np.mean(cond_list)\n",
    "        std_cond = np.std(cond_list)\n",
    "        cond_summary.loc[sample_size, file] = f\"{mean_cond:.2e} ± {std_cond:.2e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b22267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#转化条件数为5%，95%格式\n",
    "cond_quantiles = pd.DataFrame(index=sample_sizes, columns=networks)\n",
    "\n",
    "for net in networks:\n",
    "    for size in sample_sizes:\n",
    "        cond_list = cond_all[net][size]\n",
    "        q05, q95 = np.percentile(cond_list, [5, 95])\n",
    "        # 格式化为 (5%, 95%)\n",
    "        cond_quantiles.loc[size, net] = f\"({q05:.2f}, {q95:.2f})\"\n",
    "\n",
    "# 查看结果\n",
    "cond_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa2552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99238735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e237bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6c68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
