{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import warnings\n",
    "logging.getLogger('pgmpy').setLevel(logging.ERROR)\n",
    "logging.getLogger('pgmpy').setLevel(logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"networkx.utils.backends\")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import pysnooper\n",
    "import pandas as pd\n",
    "import pyagrum as gum\n",
    "import concurrent.futures\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from time import *\n",
    "import networkx as nx\n",
    "from Decom_Tree import *\n",
    "from copy import deepcopy\n",
    "os.environ[\"NUMEXPR_MAX_THREADS\"] = \"16\"\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.factors import factor_product,factor_divide\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.models import DiscreteBayesianNetwork,JunctionTree\n",
    "from pgmpy.factors.discrete import DiscreteFactor, TabularCPD\n",
    "from pgmpy.inference import VariableElimination, BeliefPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_state_names(g):\n",
    "    return {node: [0, 1] for node in list(g.nodes)}\n",
    "\n",
    "def get_random_cpds_with_labels(model, state_names, inplace=False, seed=None):\n",
    "    cpds = []\n",
    "    for node in model.nodes():\n",
    "        parents = list(model.predecessors(node))\n",
    "        cpds.append(\n",
    "            TabularCPD.get_random(\n",
    "                variable=node,\n",
    "                evidence=parents,\n",
    "                cardinality={var: 2 for var in model.nodes()},  \n",
    "                state_names=state_names, \n",
    "                seed=seed\n",
    "            )\n",
    "        )\n",
    "    if inplace:\n",
    "        model.add_cpds(*cpds)\n",
    "    else:\n",
    "        return cpds\n",
    "    \n",
    "def mar_pro(t,r):\n",
    "        \n",
    "    factors_order = [set(t.factors[i].variables) for i in range(len(t.factors))]\n",
    "    factor_copy = deepcopy(t.factors)\n",
    "\n",
    "    while t.number_of_nodes() > 0:\n",
    "\n",
    "        min_degree_node = min(t.nodes(), key=t.degree)\n",
    "\n",
    "        self_index = factors_order.index(set(min_degree_node))\n",
    "\n",
    "        S_factor = deepcopy(factor_copy[self_index]) \n",
    "        if len(t.nodes) > 1:\n",
    "\n",
    "            neibor_set = set(*t.adj[min_degree_node])\n",
    "\n",
    "            S = set(min_degree_node)&neibor_set \n",
    "\n",
    "            S_marginal_nodes = set(factor_copy[self_index].variables) - S\n",
    "\n",
    "            S_factor.marginalize(S_marginal_nodes)\n",
    "\n",
    "\n",
    "            marginal_nodes =  set(min_degree_node) - (S|set(R)) \n",
    "\n",
    "            neibor_inder = factors_order.index(neibor_set)\n",
    "\n",
    "            if len(marginal_nodes)>0:\n",
    "                factor_copy[self_index].marginalize(marginal_nodes )\n",
    "\n",
    "            factor_copy[neibor_inder] = factor_product(factor_copy[self_index],factor_copy[neibor_inder]) #P(A)P(B)\n",
    "            factor_copy[neibor_inder] = factor_divide(factor_copy[neibor_inder],S_factor)#P(A)P(B)/P(S)\n",
    "\n",
    "            #print(neibor_set,factor_copy[neibor_inder])\n",
    "\n",
    "        else:\n",
    "            marginal_nodes =  set(factor_copy[self_index].variables) - set(R)\n",
    "            #print(marginal_nodes)\n",
    "            if len(marginal_nodes)>0:\n",
    "                factor_copy[self_index].marginalize(marginal_nodes)\n",
    "\n",
    "        t.remove_node(min_degree_node)\n",
    "    \n",
    "    return factor_copy[self_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_example_model('child')\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(model.nodes)\n",
    "G.add_edges_from(model.edges)\n",
    "state_names = generate_state_names(G)\n",
    "decom = Graph_Decom(G)\n",
    "atoms = decom.Decom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a13ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute P('HypDistrib' = 0|'HypoxiaInO2' = 0) In-cluster\n",
    "logging.getLogger('pgmpy').setLevel(logging.ERROR)\n",
    "bn = DiscreteBayesianNetwork()\n",
    "bn.add_nodes_from(list(G.nodes))\n",
    "bn.add_edges_from(list(G.edges))\n",
    "\n",
    "learn_bn = DiscreteBayesianNetwork()\n",
    "learn_bn.add_nodes_from(list(G.nodes))\n",
    "learn_bn.add_edges_from(list(G.edges))\n",
    "\n",
    "sum_sub_T,sum_full_T,sum_Bias,sum_RMSE = [],[],[],[]\n",
    "for sample_size in [100,500,1000,2500,5000,7500,10000]:\n",
    "    Bias,RMSE = 0,0\n",
    "    sub_T,full_T = 0,0\n",
    "    for i in range(100):\n",
    "        bn.cpds = []\n",
    "        get_random_cpds_with_labels(bn, state_names, inplace=True)\n",
    "        ori_infer = BeliefPropagation(bn) \n",
    "        ori_query = ori_infer.query(variables = ['HypDistrib'], evidence= {'HypoxiaInO2':0}, show_progress=False).values[0] \n",
    "        df = BayesianModelSampling(bn).forward_sample(size=sample_size, show_progress=False)\n",
    "\n",
    "        \n",
    "        start = time()\n",
    "        T = decom.spann_tree()\n",
    "        C = ['HypDistrib', 'DuctFlow', 'HypoxiaInO2', 'LowerBodyO2', 'CardiacMixing', 'Disease', 'LungParench']   \n",
    "        sub_df = df[C]\n",
    "        sub_model = DiscreteBayesianNetwork(list(G.subgraph(C).edges))\n",
    "        sub_model.add_nodes_from(C)\n",
    "        sub_model.cpds = []\n",
    "        sub_model.fit(sub_df,estimator=MaximumLikelihoodEstimator)\n",
    "        sub_infer = VariableElimination(sub_model) \n",
    "        sub_query = sub_infer.query(variables = ['HypDistrib'], evidence= {'HypoxiaInO2':0}, show_progress=False).values[0] \n",
    "        sub_T += time()-start\n",
    "        Bias += abs(sub_query-ori_query)\n",
    "        RMSE += (sub_query-ori_query)**2\n",
    "\n",
    "        \n",
    "        start = time()\n",
    "        learn_bn.cpds = []\n",
    "        learn_bn.fit(df,estimator=MaximumLikelihoodEstimator)\n",
    "        full_infer = BeliefPropagation(learn_bn) \n",
    "        full_query = full_infer.query(variables = ['HypDistrib'], evidence= {'HypoxiaInO2':0}, show_progress=False).values[0]\n",
    "        full_T += time()-start\n",
    "        \n",
    "    \n",
    "    sum_sub_T.append(sub_T)\n",
    "    sum_full_T.append(full_T)\n",
    "    sum_Bias.append(Bias/100)\n",
    "    sum_RMSE.append((RMSE/100)** 0.5)\n",
    "print(sum_sub_T,sum_full_T,sum_Bias,sum_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4e82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute P('CO2Report' = 0|'Grunting' = 0) Cross-cluster\n",
    "logging.getLogger('pgmpy').setLevel(logging.ERROR)\n",
    "\n",
    "R = {'Grunting','CO2Report'}\n",
    "\n",
    "bn = DiscreteBayesianNetwork()\n",
    "bn.add_nodes_from(list(G.nodes))\n",
    "bn.add_edges_from(list(G.edges))\n",
    "\n",
    "learn_bn = DiscreteBayesianNetwork()\n",
    "learn_bn.add_nodes_from(list(G.nodes))\n",
    "learn_bn.add_edges_from(list(G.edges))\n",
    "\n",
    "sum_sub_T,sum_full_T,sum_Bias,sum_RMSE = [],[],[],[]\n",
    "for sample_size in [100,500,1000,2500,5000,7500,10000]:#\n",
    "    Bias,RMSE = 0,0\n",
    "    sub_T,full_T = 0,0\n",
    "    for i in range(100):\n",
    "\n",
    "        bn.cpds = []\n",
    "        get_random_cpds_with_labels(bn, state_names, inplace=True)\n",
    "        ori_infer = BeliefPropagation(bn) \n",
    "        ori_query = ori_infer.query(variables = ['CO2Report'], evidence= {'Grunting':0}, show_progress=False).values[0] \n",
    "        df = BayesianModelSampling(bn).forward_sample(size=sample_size, show_progress=False)\n",
    "\n",
    "\n",
    "        start = time() \n",
    "        T = decom.PPDD(R)\n",
    "        clique_trees = JunctionTree(T.edges())\n",
    "        evi_0 = 0\n",
    "        for i in list(T.nodes):\n",
    "            sub_model = DiscreteBayesianNetwork(list(G.subgraph(list(i)).edges))\n",
    "            sub_model.cpds = []\n",
    "            sub_model.fit(data=df[list(i)],estimator=MaximumLikelihoodEstimator)\n",
    "            L = [cpd.to_factor() for cpd in sub_model.cpds]\n",
    "            factors = L[0]\n",
    "            for j in range(1,len(L)):\n",
    "                factors = factor_product(factors,L[j])\n",
    "            if 'Grunting' in i:\n",
    "                sub_infer = VariableElimination(sub_model) \n",
    "                evi_0 = sub_infer.query(variables = ['Grunting'], evidence= {}, show_progress=False).values[0]\n",
    "            clique_trees.add_factors(factors)\n",
    "\n",
    "        OUR = (mar_pro(clique_trees,R).values[0][0])/evi_0\n",
    "        sub_T += (time()-start)\n",
    "        Bias += abs(OUR-ori_query)\n",
    "        RMSE += (OUR-ori_query)**2\n",
    "\n",
    "        \n",
    "        start = time()\n",
    "        learn_bn.cpds = []\n",
    "        learn_bn.fit(df,estimator=MaximumLikelihoodEstimator)\n",
    "        full_infer = BeliefPropagation(learn_bn) \n",
    "        full_query = full_infer.query(variables = ['CO2Report'], evidence= {'Grunting':0}, show_progress=False).values[0]\n",
    "        full_T += time()-start\n",
    "\n",
    "    \n",
    "    sum_sub_T.append(sub_T)\n",
    "    sum_full_T.append(full_T)\n",
    "    sum_Bias.append(Bias/100)\n",
    "    sum_RMSE.append((RMSE/100)** 0.5)\n",
    "print(sum_sub_T,sum_full_T,sum_Bias,sum_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac51fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyPy",
   "language": "python",
   "name": "pypy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
