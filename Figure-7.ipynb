{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc48a105-0d4a-4c44-9334-42f750e0a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "logging.getLogger('pgmpy').setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"networkx.utils.backends\")\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import random\n",
    "from Decom_Tree import *\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.linalg import inv, det\n",
    "from pgmpy.global_vars import logger\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.factors.continuous import LinearGaussianCPD\n",
    "from pgmpy.models import  LinearGaussianBayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c2a1ef-dc8b-46a0-b64f-7ae0a02f0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cpds(self, loc=0, scale=1, inplace=False, seed=None):\n",
    "    seed = seed if seed is not None else int(time.time() * 1000)\n",
    "    cpds = []\n",
    "    for i, var in enumerate(self.nodes()):\n",
    "        parents = self.get_parents(var)\n",
    "        cpds.append(\n",
    "            LinearGaussianCPD.get_random(\n",
    "                variable=var,\n",
    "                evidence=parents,\n",
    "                loc=loc,\n",
    "                scale=scale,\n",
    "                seed=(seed + i),\n",
    "            )\n",
    "        )\n",
    "    if inplace:\n",
    "        self.add_cpds(*cpds)\n",
    "    else:\n",
    "        return cpds\n",
    "\n",
    "#ecoli70 46 26 19\n",
    "#magic-niab 44 9 33\n",
    "#magic-irri 64 9 43\n",
    "#arth150 107 82 24\n",
    "#[ \"ecoli70\",\"magic-niab\",\"magic-irri\",\"arth150\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d589ab5d-0bf5-48da-a126-bafac94ef400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(mu1, cov1, mu2, cov2):\n",
    "    \"\"\"\n",
    "    Compute the Kullbackâ€“Leibler (KL) divergence between two multivariate Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        mu1 (ndarray): Mean vector of the first distribution.\n",
    "        cov1 (ndarray): Covariance matrix of the first distribution.\n",
    "        mu2 (ndarray): Mean vector of the second distribution.\n",
    "        cov2 (ndarray): Covariance matrix of the second distribution.\n",
    "        \n",
    "    Returns:\n",
    "        float: KL divergence D_KL(N(mu1, cov1) || N(mu2, cov2))\n",
    "    \"\"\"\n",
    "    d = len(mu1)  # Dimensionality of the distributions\n",
    "    term1 = np.trace(np.dot(inv(cov2), cov1))  # Tr(Sigma_2^-1 * Sigma_1)\n",
    "    term2 = np.dot(np.dot((mu2 - mu1).T, inv(cov2)), (mu2 - mu1))  # (mu2 - mu1)^T * Sigma_2^-1 * (mu2 - mu1)\n",
    "    term3 = np.log(det(cov2) / det(cov1))  # log(det(Sigma_2) / det(Sigma_1))\n",
    "    kl_divergence = 0.5 * (term1 + term2 - d + term3)\n",
    "    return kl_divergence\n",
    "\n",
    "\n",
    "def hellinger_distance(mu1, cov1, mu2, cov2):\n",
    "    \"\"\"\n",
    "    Compute the Hellinger distance between two multivariate Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        mu1 (ndarray): Mean vector of the first distribution.\n",
    "        cov1 (ndarray): Covariance matrix of the first distribution.\n",
    "        mu2 (ndarray): Mean vector of the second distribution.\n",
    "        cov2 (ndarray): Covariance matrix of the second distribution.\n",
    "        \n",
    "    Returns:\n",
    "        float: Hellinger distance H(N(mu1, cov1), N(mu2, cov2))\n",
    "    \"\"\"\n",
    "    # Compute the determinants of the covariance matrices\n",
    "    det_cov1 = det(cov1)\n",
    "    det_cov2 = det(cov2)\n",
    "    \n",
    "    # Compute the average of the two covariance matrices\n",
    "    avg_cov = (cov1 + cov2) / 2\n",
    "    \n",
    "    # Compute the exponent term in the Hellinger distance formula\n",
    "    diff_mu = mu1 - mu2\n",
    "    term = np.dot(np.dot(diff_mu.T, inv(avg_cov)), diff_mu)  # (mu1 - mu2)^T * Sigma_avg^-1 * (mu1 - mu2)\n",
    "    exponent = -0.125 * term\n",
    "    \n",
    "    # Compute the squared Hellinger distance\n",
    "    hellinger_squared = 1 - (det_cov1 ** 0.25) * (det_cov2 ** 0.25) / (det(avg_cov) ** 0.5) * np.exp(exponent)\n",
    "    return np.sqrt(hellinger_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ac8ee58-e657-4601-bb7e-d8d7a17781c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoli70\n",
      "magic-niab\n",
      "    ecoli70                                                                  \\\n",
      "      500               1000              2500              5000              \n",
      "       klPQ hellinger    klPQ hellinger    klPQ hellinger    klPQ hellinger   \n",
      "1    0.1887    0.2122  0.0747    0.1358  0.0361    0.0948  0.0171    0.0652   \n",
      "2    0.1388    0.1846  0.0783    0.1386  0.0334    0.0909  0.0149    0.0609   \n",
      "3    0.1799    0.2067  0.0874    0.1467  0.0288    0.0846  0.0151    0.0614   \n",
      "4    0.1399    0.1851  0.0994    0.1562  0.0333    0.0911  0.0154     0.062   \n",
      "5    0.1802    0.2072  0.0952    0.1528  0.0293    0.0857  0.0175     0.066   \n",
      "..      ...       ...     ...       ...     ...       ...     ...       ...   \n",
      "96    0.173     0.203  0.0912    0.1502  0.0343    0.0921  0.0165    0.0643   \n",
      "97   0.1602    0.1955  0.0804     0.141   0.039    0.0985  0.0156    0.0623   \n",
      "98   0.1762    0.2064  0.0901    0.1495   0.031    0.0881  0.0188    0.0684   \n",
      "99   0.1722    0.2039  0.0701    0.1311  0.0281    0.0836  0.0144    0.0599   \n",
      "100  0.1531    0.1933  0.0811    0.1407  0.0353    0.0936  0.0159    0.0631   \n",
      "\n",
      "                       ... magic-niab                                      \\\n",
      "      7500             ...      1000              2500              5000    \n",
      "       klPQ hellinger  ...       klPQ hellinger    klPQ hellinger    klPQ   \n",
      "1    0.0129    0.0567  ...     0.0669    0.1284  0.0282    0.0837  0.0139   \n",
      "2    0.0118    0.0544  ...     0.0724    0.1339  0.0308    0.0874  0.0112   \n",
      "3    0.0092    0.0478  ...     0.0696    0.1301  0.0274    0.0826  0.0168   \n",
      "4    0.0103    0.0507  ...      0.081    0.1419  0.0225    0.0746   0.014   \n",
      "5    0.0098    0.0495  ...     0.0636    0.1251  0.0311    0.0881  0.0155   \n",
      "..      ...       ...  ...        ...       ...     ...       ...     ...   \n",
      "96    0.012    0.0547  ...     0.0941    0.1517  0.0347    0.0929  0.0164   \n",
      "97   0.0112    0.0528  ...     0.0818    0.1422  0.0261    0.0807  0.0183   \n",
      "98   0.0089    0.0472  ...     0.0975    0.1535  0.0259    0.0807  0.0176   \n",
      "99   0.0088    0.0469  ...     0.0606    0.1223  0.0351    0.0932  0.0152   \n",
      "100  0.0127    0.0563  ...     0.0738    0.1356   0.031    0.0876  0.0168   \n",
      "\n",
      "                                                   \n",
      "                7500              10000            \n",
      "    hellinger    klPQ hellinger    klPQ hellinger  \n",
      "1      0.0588  0.0093    0.0481  0.0067    0.0409  \n",
      "2       0.053  0.0093    0.0481  0.0064    0.0399  \n",
      "3      0.0649   0.012    0.0549  0.0077    0.0437  \n",
      "4      0.0594  0.0096    0.0488  0.0065    0.0404  \n",
      "5      0.0622   0.011    0.0523   0.007    0.0419  \n",
      "..        ...     ...       ...     ...       ...  \n",
      "96     0.0639  0.0112    0.0529  0.0074    0.0431  \n",
      "97     0.0675  0.0109    0.0522  0.0079    0.0444  \n",
      "98     0.0661  0.0107    0.0516  0.0086    0.0463  \n",
      "99     0.0616  0.0102    0.0505  0.0082    0.0453  \n",
      "100    0.0647    0.01      0.05  0.0084    0.0458  \n",
      "\n",
      "[100 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = pd.MultiIndex.from_product(\n",
    "    [[ \"ecoli70\", \"magic-niab\",\"magic-irri\", \"arth150\"], \n",
    "     [500, 1000, 2500, 5000, 7500, 10000],  \n",
    "     [\"klPQ\", \"hellinger\"]]  \n",
    ")\n",
    "\n",
    "result_continue = pd.DataFrame(columns=columns)\n",
    "\n",
    "for file in [ \"ecoli70\", \"magic-niab\",\"magic-irri\", \"arth150\"]:\n",
    "    print(file)\n",
    "    save_file = f'{file}.bif' \n",
    "    learn_file = f'{file}1.bif' \n",
    "    model = get_example_model(file)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(model.nodes)\n",
    "    G.add_edges_from(model.edges)\n",
    "    decom = Graph_Decom(G)\n",
    "    atoms = decom.Decom()\n",
    "    for sample_size in [500, 1000, 2500, 5000, 7500, 10000]:\n",
    "        succ_num = 100\n",
    "        row = 0\n",
    "        while succ_num:\n",
    "            bn = LinearGaussianBayesianNetwork()\n",
    "            bn.add_nodes_from(list(G.nodes))\n",
    "            bn.add_edges_from(list(G.edges)) \n",
    "            get_random_cpds(bn, inplace=True)\n",
    "            df = bn.simulate(sample_size)\n",
    "            \n",
    "            learn_bn = LinearGaussianBayesianNetwork()\n",
    "            learn_bn.add_nodes_from(list(G.nodes))\n",
    "            learn_bn.add_edges_from(list(G.edges))\n",
    "            \n",
    "            learn_bn.cpds = []\n",
    "            Traverse = []\n",
    "            for i in atoms:\n",
    "                sub_model = LinearGaussianBayesianNetwork(list(G.subgraph(list(i)).edges))\n",
    "                sub_model.add_nodes_from(i)\n",
    "                sub_model.cpds = []\n",
    "                sub_model.fit(df[list(i)])\n",
    "                for node in i:\n",
    "                    if node not in Traverse:\n",
    "                        if len(model.get_parents(node)) == len(sub_model.get_parents(node)):\n",
    "                            Traverse.append(node)\n",
    "                            learn_bn.add_cpds(sub_model.get_cpds(node))\n",
    "    \n",
    "            mean, cov = bn.to_joint_gaussian()\n",
    "            mean_learn, cov_learn = learn_bn.to_joint_gaussian()\n",
    "            kl_value = kl_divergence(mean, cov, mean_learn, cov_learn)\n",
    "            hellinger_value = hellinger_distance(mean, cov, mean_learn, cov_learn)\n",
    "            for metric_name, value in [(\"klPQ\", kl_value), (\"hellinger\", hellinger_value)]:\n",
    "                result_continue.loc[row + 1, (file, sample_size, metric_name)] = round(value, 4)                \n",
    "            succ_num -= 1\n",
    "            row += 1        \n",
    "\n",
    "print(result_continue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyPy",
   "language": "python",
   "name": "pypy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
